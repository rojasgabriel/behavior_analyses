{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f4eb5a",
   "metadata": {},
   "source": [
    "## Fitting psychometric functions with more advanced statistics packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8daff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from djchurchland.schema import Session, Task # import all schemas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ses = pd.DataFrame((Session*Task.TrialSet() & 'subject_name = \"JC098\"' & 'session_datetime = \"2023-02-15 15:12:48\"').fetch());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95def70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>PsychometricRegression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>               <td>y</td>           <th>  Log-Likelihood:    </th> <td> -324.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>PsychometricRegression</td> <th>  AIC:               </th> <td>   656.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Maximum Likelihood</td>   <th>  BIC:               </th> <td>   673.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                <td>Mon, 06 Mar 2023</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                    <td>14:30:49</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>         <td>   558</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>             <td>   554</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                 <td>     0</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bias</th>   <td>    0.3907</td> <td>    6.243</td> <td>    0.063</td> <td> 0.950</td> <td>  -11.844</td> <td>   12.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>  <td>   27.5002</td> <td>    8.713</td> <td>    3.156</td> <td> 0.002</td> <td>   10.424</td> <td>   44.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gamma1</th> <td>         0</td> <td>    0.154</td> <td>        0</td> <td> 1.000</td> <td>   -0.301</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gamma2</th> <td>         0</td> <td>    0.181</td> <td>        0</td> <td> 1.000</td> <td>   -0.354</td> <td>    0.354</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          PsychometricRegression Results                          \n",
       "==================================================================================\n",
       "Dep. Variable:                          y   Log-Likelihood:                -324.26\n",
       "Model:             PsychometricRegression   AIC:                             656.5\n",
       "Method:                Maximum Likelihood   BIC:                             673.8\n",
       "Date:                    Mon, 06 Mar 2023                                         \n",
       "Time:                            14:30:49                                         \n",
       "No. Observations:                     558                                         \n",
       "Df Residuals:                         554                                         \n",
       "Df Model:                               0                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "bias           0.3907      6.243      0.063      0.950     -11.844      12.626\n",
       "slope         27.5002      8.713      3.156      0.002      10.424      44.576\n",
       "gamma1              0      0.154          0      1.000      -0.301       0.301\n",
       "gamma2              0      0.181          0      1.000      -0.354       0.354\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the third cell before running this or import from btss\n",
    "# rom btss.task_utils import fit_psychometric\n",
    "\n",
    "x = ses.iloc[0].stim_values        # stim amplitudes\n",
    "y = ses.iloc[0].response_values    # responses to the left 1, right -1 or no response 0\n",
    "x = x[(np.isfinite(y)) & (y!= 0)]  # discard trials with no response\n",
    "y = y[(np.isfinite(y)) & (y!= 0)]  # responses to the left (or right)\n",
    "\n",
    "\n",
    "res = fit_psychometric(x,y==1)\n",
    "%matplotlib qt\n",
    "import pylab as plt\n",
    "plt.plot(res['stims'],res['p_side'],'ko')\n",
    "for s,c in zip(res['stims'],res['p_side_ci']):\n",
    "    plt.plot(s*np.array([1,1]),c,'k-_')\n",
    "nx = np.linspace(-20,20,100)\n",
    "plt.plot(nx,res['function'](*res['fit_params'],nx))\n",
    "res['fit'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f0397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is from github.com/jcouto/btss\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy.special import erfc # import the complementary error function\n",
    "from scipy.special import erf # import the error function\n",
    "# This has example ways to fit the psychometric function and getting confidence intervals\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# weibull fit\n",
    "def weibull(bias, slope, gamma1, gamma2, X):\n",
    "    ''' weibull function with lapse rates\n",
    "    '''\n",
    "    return gamma1 + (1. - gamma1 - gamma2) * (erf((X - bias) / slope) + 1.) / 2.\n",
    "\n",
    "# log likelihood when using minimize\n",
    "def neg_log_likelihood_error(func, parameters, X, Y):\n",
    "    '''\n",
    "    Compute the log likelihood\n",
    "\n",
    "    'func' is the (psychometric) function \n",
    "    'parameters' are the input parameters to 'func'\n",
    "    'Y' is the binary response (correct = 1; incorrect=0)\n",
    "    Joao Couto - Jan 2022    \n",
    "    '''\n",
    "\n",
    "    pX = func(*parameters, X)*0.99 + 0.005  # the predicted performance for X from the PMF\n",
    "    # epsilon to prevent error in log(0)\n",
    "    val = np.nansum(Y*np.log(pX) + (1-Y)*np.log(1-pX))\n",
    "    return -1*val\n",
    "\n",
    "def compute_proportions(stim_values, response_values):\n",
    "    '''\n",
    "    Computes the proportion of responses to each stimulus value.\n",
    "Returns: \n",
    "    - stims    - unique stimulus intensities\n",
    "    - p_side   - proportion of trials to the side\n",
    "    - ci_side  - confidance intervals from binomial distribution with the wilson method\n",
    "    - n_obs    - number of observations (trials for each)\n",
    "    - n_side   - number of trials to the specific side\n",
    "\n",
    "\n",
    "Joao Couto - Jan 2023\n",
    "    '''\n",
    "    \n",
    "    stims = np.unique(stim_values)\n",
    "    p_side = np.zeros_like(stims,dtype=float) \n",
    "    ci_side = np.zeros((len(stims),2),dtype=float)\n",
    "    n_obs = np.zeros_like(stims,dtype=float)\n",
    "    n_side = np.zeros_like(stims,dtype=float)\n",
    "    for i,intensity in enumerate(stims):\n",
    "        # number of times the subject licked to one of the sides \n",
    "        cnt = np.sum(response_values[stim_values == intensity]) \n",
    "        nobs = np.sum(stim_values == intensity) # number of observations (ntrials)\n",
    "        n_obs[i] = nobs\n",
    "        n_side[i] = cnt\n",
    "        p_side[i] = cnt/nobs\n",
    "        ci_side[i] = proportion_confint(cnt,nobs,method='wilson') # 95% confidence interval\n",
    "    return stims,p_side,ci_side,n_obs,n_side\n",
    "\n",
    "# statsmodels gives confidence and p values for the fit\n",
    "class PsychometricRegression(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, exog, func = None, bounds = None,startpar_function = None,parnames = None, **kwds):\n",
    "        '''\n",
    "        Fits a psychometric with constraints function (constrained weibull e.g.)\n",
    "        \n",
    "        This is part of the tools for github.com/jcouto/btss\n",
    "        \n",
    "        Inputs:\n",
    "            endog - are the response values for each trial\n",
    "            exog  - are the stim intensities for each trial\n",
    "            func  - the function to fit; default weibull with lapses\n",
    "            bound - the constraints to the fit; default [(min(x),max(x)),(0.01,1000),(0,1),(0,1)]\n",
    "            startpar_function - a function to get the start guess for the fit\n",
    "            parnames - the names of the fit parameters\n",
    "            \n",
    "        Usage:\n",
    "        \n",
    "        ft = PsychometricRegression(response_values.astype(float),\n",
    "                                    exog = stim_values.astype(float))\n",
    "        res = ft.fit(min_required_stim_values = min_required_stim_values, full_output=True)\n",
    "        print(res.summary())\n",
    "            \n",
    "        Joao Couto - Feb 2023\n",
    "        '''\n",
    "\n",
    "        super(PsychometricRegression, self).__init__(endog, exog, **kwds)\n",
    "        if not func is None:\n",
    "            self.fit_function = func\n",
    "            self.bounds = None\n",
    "            self.get_start_params = startpar_function\n",
    "            if not parnames is None:\n",
    "                self.exog_names[:] = parnames\n",
    "        else:\n",
    "            self.fit_function = weibull\n",
    "            self.exog_names[:] = ['bias','slope','gamma1','gamma2']\n",
    "            self.bounds = [(np.min(self.exog[:,0]),np.max(self.exog[:,0])),\n",
    "                           (0.01,1000),\n",
    "                           (0,1),(0,1)]\n",
    "            self.get_start_params  = lambda x,y: [0,np.max(x)/2,y[0],1-y[-1]]\n",
    "            \n",
    "    \n",
    "    def loglikeobs(self,params):\n",
    "        pX = self.fit_function(*params, self.exog[:,0])\n",
    "        pX[pX==0] = 0.001\n",
    "        pX[pX==1] = 0.999\n",
    "        # the predicted performance for X from the PMF\n",
    "        val = np.nansum(self.endog*np.log(pX) + (1-self.endog)*np.log(1-pX))\n",
    "        return val\n",
    "    \n",
    "    def fit(self, start_params=None,\n",
    "            maxiter=100000,\n",
    "            maxfun=10000,\n",
    "            min_required_stim_values=6, **kwds):\n",
    "\n",
    "        self.stims, self.p_side, self.ci_side, self.n_obs,self.n_side = compute_proportions(self.exog[:,0], self.endog)\n",
    "        if len(self.stims) < min_required_stim_values:\n",
    "            return None\n",
    "        \n",
    "        if start_params == None:\n",
    "            # Reasonable starting values\n",
    "            if not self.get_start_params is None:\n",
    "                start_params = self.get_start_params(self.stims, self.p_side)\n",
    "        if start_params is None:\n",
    "            raise(ValueError(\"Need to provide start parameters or a function to compute them.\"))\n",
    "        self.df_null = 0\n",
    "        self.k_constant = len(start_params)\n",
    "        self.df_resid = len(self.endog)-len(start_params)\n",
    "        return super(PsychometricRegression, self).fit(\n",
    "            start_params=start_params,\n",
    "            maxiter=maxiter,\n",
    "            maxfun=maxfun,\n",
    "            method = 'lbfgs',\n",
    "            bounds = self.bounds,\n",
    "            disp = False,\n",
    "            **kwds)\n",
    "        \n",
    "# main function to fit and compute statistics\n",
    "def fit_psychometric(stim_values, response_values,\n",
    "                     func = weibull,    # to fit the psychometric\n",
    "                     min_required_stim_values = 6,  # min values required to fit the function\n",
    "                     method = 'PsychometricRegression'):#'Nelder-Mead'):#'L-BFGS-B'):\n",
    "    '''\n",
    "    Fits a psychometric curve and computes points\n",
    "    \n",
    "    Joao Couto - Jan 2023\n",
    "    '''\n",
    "    if method == 'PsychometricRegression':\n",
    "        # use PsychometricRegression (default weibull)\n",
    "        ft = PsychometricRegression(response_values.astype(float),\n",
    "                                    exog = stim_values.astype(float))\n",
    "        res = ft.fit(min_required_stim_values = min_required_stim_values, full_output=True)\n",
    "        if res is None:\n",
    "            fit_res = None\n",
    "            params = None\n",
    "        else:\n",
    "            fit_res = res\n",
    "            params = res.params\n",
    "        return dict(stims = ft.stims,\n",
    "                    p_side = ft.p_side,\n",
    "                    p_side_ci = ft.ci_side,\n",
    "                    n_side = ft.n_side,\n",
    "                    n_obs = ft.n_obs,\n",
    "                    fit_params = params,\n",
    "                    fit = fit_res,\n",
    "                    function = ft.fit_function)\n",
    "    \n",
    "    stims,p_side,ci_side,n_obs,n_side = compute_proportions(stim_values, response_values)\n",
    "    fit_res = None\n",
    "    params = None\n",
    "    if len(stims) >= min_required_stim_values and not func is None:\n",
    "\n",
    "        opt_func = lambda pars: neg_log_likelihood_error(func, pars, \n",
    "                                                     stim_values,\n",
    "                                                     response_values)\n",
    "        # x0 is the initial guess for the fit, it is an important parameter\n",
    "        x0 = [0.,0.1,p_side[0],1 - p_side[-1]]\n",
    "        bounds = [(stims[0],stims[-1]),(0.0001,10),(0,0.7),(0,.7)]\n",
    "        #import warnings\n",
    "        #warnings.filterwarnings('ignore')\n",
    "        options = dict(maxiter = 500*len(x0))\n",
    "        if 'Neder' in method:\n",
    "            options['adaptive'] = True\n",
    "        fit_res = minimize(opt_func, x0,\n",
    "                           options = options,\n",
    "                           bounds = bounds, method = method)\n",
    "        params = fit_res.x\n",
    "    return dict(stims = stims,\n",
    "                p_side = p_side,\n",
    "                p_side_ci = ci_side,\n",
    "                n_side = n_side,\n",
    "                n_obs = n_obs,\n",
    "                fit_params = params,\n",
    "                fit = fit_res,\n",
    "                function = func)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
